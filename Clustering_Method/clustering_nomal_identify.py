# Identify nomal clusters and anomalous clusters with nomal data
# Input 'data' is initial data

import numpy as np
# from utils.class_row import nomal_class_data

# Change function signature:
# data_features_for_clustering: NumPy array of features used for clustering (e.g. X_reduced, shape (N, 10))
# original_labels_aligned: original labels for each row in data_features_for_clustering (0 or 1, shape (N,))
# clusters_assigned: cluster IDs assigned to each row in data_features_for_clustering (shape (N,))
# num_total_clusters: total number of clusters generated by the clustering algorithm
def clustering_nomal_identify(data_features_for_clustering, original_labels_aligned, clusters_assigned, num_total_clusters):
    
    print(f"\n[DEBUG CNI] Received 'data_features_for_clustering' - Shape: {data_features_for_clustering.shape}")
    if data_features_for_clustering.ndim == 2:
        print(f"[DEBUG CNI]   NumPy array - First 5 cols of first row: {data_features_for_clustering[0, :5] if data_features_for_clustering.shape[0] > 0 and data_features_for_clustering.shape[1] >=5 else 'N/A or too small'}")
    print(f"[DEBUG CNI] Received 'original_labels_aligned' - Shape: {original_labels_aligned.shape}, Unique values: {np.unique(original_labels_aligned, return_counts=True)}")
    print(f"[DEBUG CNI] Received 'clusters_assigned' - Shape: {clusters_assigned.shape}, Unique values: {np.unique(clusters_assigned, return_counts=True)}")
    print(f"[DEBUG CNI] Received 'num_total_clusters': {num_total_clusters}")

    # Extract only normal samples (Label == 0) from the feature space used for clustering
    known_normal_samples_features = data_features_for_clustering[original_labels_aligned == 0]
    print(f"[DEBUG CNI] 'known_normal_samples_features' (from X_reduced space) - Shape: {known_normal_samples_features.shape}")
    if known_normal_samples_features.ndim == 2 and known_normal_samples_features.shape[0] > 0 :
         print(f"[DEBUG CNI]   NumPy array - First 5 cols of first row: {known_normal_samples_features[0, :5] if known_normal_samples_features.shape[1] >=5 else 'N/A or too small'}")


    # final_labels is for the original data length (N), so it's the same length as clusters_assigned
    final_labels = np.zeros(len(data_features_for_clustering), dtype=int) # Default value can also be set to 0 (normal) or -1 (unallocated)
    threshold = 0.3

    for cluster_id in range(num_total_clusters): # num_total_clusters can be the K-value returned by the algorithm
        # create a mask corresponding to the current cluster_id in the clusters_assigned array
        cluster_mask = (clusters_assigned == cluster_id)

        if not np.any(cluster_mask): # If there are no data points assigned to this cluster ID, skip it
            # print(f"[INFO CNI] Cluster {cluster_id} is empty. Skipping.")
            continue

        # Extract data from the feature space used for clustering
        current_cluster_features = data_features_for_clustering[cluster_mask]
        # print(f"[DEBUG CNI] 'current_cluster_features' (cluster_id {cluster_id}, from X_reduced space) - Shape: {current_cluster_features.shape}")

        if current_cluster_features.size == 0 or known_normal_samples_features.size == 0:
            num_normal_in_cluster = 0
        else:
            # Now current_cluster_features and known_normal_samples_features are in the same feature space (e.g. 10 features)
            try:
                # Compare all pairs (still possible memory issues, especially for large data like Kitsune)
                # A[:, None, :] is (len_A, 1, n_features)
                # B[None, :, :] is (1, len_B, n_features)
                # The comparison result is (len_A, len_B, n_features)
                comparison_matrix = (current_cluster_features[:, None, :] == known_normal_samples_features[None, :, :])
                # print(f"DEBUG: comparison_matrix shape for cluster {cluster_id}: {comparison_matrix.shape}")
                all_features_match = np.all(comparison_matrix, axis=2) # (len_A, len_B)
                # print(f"DEBUG: all_features_match shape for cluster {cluster_id}: {all_features_match.shape}")
                any_known_normal_matches = np.any(all_features_match, axis=1) # (len_A,)
                # print(f"DEBUG: any_known_normal_matches shape for cluster {cluster_id}: {any_known_normal_matches.shape}")
                num_normal_in_cluster = np.sum(any_known_normal_matches)
                
            except ValueError as e:
                print(f"[Error CNI comparing cluster {cluster_id}] shape mismatch or other ValueError: {e}")
                print(f"  Cluster features shape: {current_cluster_features.shape}, Known normal features shape: {known_normal_samples_features.shape}")
                num_normal_in_cluster = 0
            except MemoryError as me: # Explicitly handle MemoryError
                print(f"[Error CNI comparing cluster {cluster_id}] MemoryError: {me}")
                print(f"  Could not perform comparison due to memory constraints. Treating as 0 normal samples for this cluster.")
                num_normal_in_cluster = 0
    
        # len(current_cluster_features) is current_cluster_features.shape[0]
        normal_ratio = num_normal_in_cluster / len(current_cluster_features) if len(current_cluster_features) > 0 else 0
            
        label_for_final_output = 0 if normal_ratio >= threshold else 1
        final_labels[cluster_mask] = label_for_final_output # Use cluster_mask to ensure correct placement

    return final_labels